{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhm11/titanic_tensorflow/blob/main/Copy_of_fds_assessment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv"
      ],
      "metadata": {
        "id": "dNwNoqL9mGUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a28a50-c3d5-4257-a162-1ece24c65f59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.11/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YYu0xoyYiWRU"
      },
      "outputs": [],
      "source": [
        "### Import all Libraries required and Download NLTK Resources\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import arxiv\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud ## for\n",
        "\n",
        "# ml and nlp libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import nltk\n",
        "\n",
        "# error handling\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('vader_lexicon', quiet=True)  # For sentiment analysis\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading NLTK resources: {e}\")\n",
        "    print(\"Attempting alternative download method...\")\n",
        "    nltk.download('popular')  # Download popular packages which include punkt, stopwords and wordnet\n",
        "\n",
        "# Import NLTK modules\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of Text Analytics\n",
        "## 1. Text Data Analytics Importance\n",
        "\n",
        "Text data analytics is the process of examining, processing, and extracting meaningful insights from textual data. It's important because:\n",
        "\n",
        "1. **Unstructured data dominance**: Over 80% of business data is unstructured, with text being a primary format\n",
        "2. **Customer insights**: Reveals customer sentiment, preferences, and behavior patterns\n",
        "3. **Competitive intelligence**: Helps track market trends and competitor activities\n",
        "4. **Automated decision-making**: Powers recommendation systems and chatbots\n",
        "5. **Risk management**: Identifies potential issues in communications and social media\n",
        "\n",
        "Common tasks in text analytics include:\n",
        "- **Text preprocessing**: Cleaning and standardizing text\n",
        "- **Feature extraction**: Converting text to numerical representations\n",
        "- **Sentiment analysis**: Determining emotional tone\n",
        "- **Topic modeling**: Discovering themes in document collections\n",
        "- **Text classification**: Categorizing documents\n",
        "\n"
      ],
      "metadata": {
        "id": "iYv3uPvWibdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Extraction Function\n",
        "def extract_papers_with_citations(query, max_results=100, save_directory='research_papers'):\n",
        "    \"\"\"\n",
        "    Extract papers from arXiv based on a search query,\n",
        "    estimate citations using Semantic Scholar API,\n",
        "    and save the text data to files\n",
        "    \"\"\"\n",
        "    # Creating directory if it doesn't exist\n",
        "    if not os.path.exists(save_directory):\n",
        "        os.makedirs(save_directory)\n",
        "        print(f\"Created directory: {save_directory}\")\n",
        "\n",
        "    # Creating data directory for text files\n",
        "    text_directory = os.path.join(save_directory, 'text_data')\n",
        "    if not os.path.exists(text_directory):\n",
        "        os.makedirs(text_directory)\n",
        "        print(f\"Created directory: {text_directory}\")\n",
        "\n",
        "    # Create a client with appropriate parameters for search query and results\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Create a search query\n",
        "    search = arxiv.Search(\n",
        "        query=query,\n",
        "        max_results=max_results,\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    # Get the results into a data frame\n",
        "    papers = []\n",
        "    print(f\"Fetching {max_results} papers on '{query}' from arXiv...\")\n",
        "\n",
        "    for i, result in enumerate(tqdm(client.results(search), total=max_results)):\n",
        "        paper_id = result.entry_id.split('/')[-1]\n",
        "\n",
        "        # Extract paper information\n",
        "        paper = {\n",
        "            'arxiv_id': paper_id,\n",
        "            'title': result.title,\n",
        "            'abstract': result.summary,\n",
        "            'authors': [author.name for author in result.authors],\n",
        "            'categories': [cat for cat in result.categories],\n",
        "            'published': result.published.strftime('%Y-%m-%d'),\n",
        "            'pdf_url': result.pdf_url\n",
        "        }\n",
        "\n",
        "        # Get citation count from Semantic Scholar API\n",
        "        try:\n",
        "            paper['citation_count'] = get_citation_count(paper_id)\n",
        "            # Rate limiting to avoid API throttling\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting citation count for {paper_id}: {e}\")\n",
        "            paper['citation_count'] = 0\n",
        "\n",
        "        papers.append(paper)\n",
        "\n",
        "        # Save text data to file\n",
        "        save_paper_text(paper, text_directory, i)\n",
        "\n",
        "    # Create DataFrame\n",
        "    papers_df = pd.DataFrame(papers)\n",
        "\n",
        "    # Sort by citation count (highest first)\n",
        "    papers_df = papers_df.sort_values(by='citation_count', ascending=False)\n",
        "\n",
        "    # Save the DataFrame to CSV\n",
        "    csv_path = os.path.join(save_directory, 'research_papers.csv')\n",
        "    papers_df.to_csv(csv_path, index=False)\n",
        "    print(f\"Saved paper metadata to {csv_path}\")\n",
        "\n",
        "    # Save full JSON data for tableau , because i need to import the data using json\n",
        "    json_path = os.path.join(save_directory, 'research_papers.json')\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(papers_df.to_dict('records'), f, indent=2)\n",
        "    print(f\"Saved paper data to {json_path}\")\n",
        "\n",
        "    return papers_df\n",
        "\n",
        "#getting citation count from semantic scholar but the search is for recent ones , so it wont show much options with citations\n",
        "#getting citation count for each paper\n",
        "def get_citation_count(arxiv_id):\n",
        "    \"\"\"Get citation count from Semantic Scholar API for an arXiv paper\"\"\"\n",
        "    url = f\"https://api.semanticscholar.org/v1/paper/arXiv:{arxiv_id}\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        return data.get('citationCount', 0)\n",
        "    elif response.status_code == 404:\n",
        "        return 0\n",
        "    else:\n",
        "        response.raise_for_status()\n",
        "\n",
        "# raw data storage for checking validity\n",
        "def save_paper_text(paper, directory, index):\n",
        "    \"\"\"Save paper text (title and abstract) to a text file\"\"\"\n",
        "    filename = f\"{index:04d}_{paper['arxiv_id']}.txt\"\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"Title: {paper['title']}\\n\\n\")\n",
        "        f.write(f\"Authors: {', '.join(paper['authors'])}\\n\\n\")\n",
        "        f.write(f\"Published: {paper['published']}\\n\\n\")\n",
        "        f.write(f\"Categories: {', '.join(paper['categories'])}\\n\\n\")\n",
        "        f.write(f\"Citation Count: {paper['citation_count']}\\n\\n\")\n",
        "        f.write(f\"Abstract:\\n{paper['abstract']}\\n\\n\")\n",
        "        f.write(f\"PDF URL: {paper['pdf_url']}\\n\")\n",
        "\n",
        "    return filepath\n"
      ],
      "metadata": {
        "id": "hbXI63jYiXRt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by removing special characters, converting to lowercase,\n",
        "    removing stopwords, and lemmatizing\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Remove special characters and numbers\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # some extra stop words which are specific in research papers\n",
        "\n",
        "        academic_stop_words = {'et', 'al', 'fig', 'figure', 'table', 'paper', 'using', 'show', 'result', 'results', 'study', 'studies', 'method', 'methods'}\n",
        "        stop_words.update(academic_stop_words)\n",
        "        # extra only words which are greater than 2 length\n",
        "        tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "\n",
        "        # Lemmatize the data using word net lemmatizer\n",
        "\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocessing: {e}\")\n",
        "        # if nltk fails then normal preprocessign\n",
        "\n",
        "        if isinstance(text, str):\n",
        "            return ' '.join([word.lower() for word in re.sub(r'[^a-zA-Z\\s]', '', text).split() if len(word) > 2])\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "T3pWbZ2_ih7i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction BAG OF WORDS AND TF-IDF\n",
        "def extract_features(papers_df):\n",
        "    \"\"\"\n",
        "    Extract features from paper abstracts using Bag of Words and TF-IDF\n",
        "    \"\"\"\n",
        "    # Apply preprocessing to abstracts\n",
        "    papers_df['processed_abstract'] = papers_df['abstract'].apply(preprocess_text)\n",
        "\n",
        "    # Bag of Words\n",
        "    bow_vectorizer = CountVectorizer(max_features=1000, ngram_range=(1, 2))\n",
        "    bow_features = bow_vectorizer.fit_transform(papers_df['processed_abstract'])\n",
        "\n",
        "    # TF-IDF\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
        "    tfidf_features = tfidf_vectorizer.fit_transform(papers_df['processed_abstract'])\n",
        "\n",
        "    print(\"\\nBag of Words shape:\", bow_features.shape)\n",
        "    print(\"TF-IDF shape:\", tfidf_features.shape)\n",
        "\n",
        "    # Display top terms from the first document which occur most often\n",
        "    def display_top_features(feature_matrix, feature_names, doc_idx=0, top_n=10):\n",
        "        doc_features = feature_matrix[doc_idx].toarray()[0]\n",
        "        top_indices = doc_features.argsort()[-top_n:][::-1]\n",
        "        top_terms = [(feature_names[i], doc_features[i]) for i in top_indices]\n",
        "        return top_terms\n",
        "\n",
        "    print(\"\\nTop 10 BoW terms from first document:\")\n",
        "\n",
        "    bow_feature_names = bow_vectorizer.get_feature_names_out()\n",
        "    print(display_top_features(bow_features, bow_feature_names))\n",
        "\n",
        "    print(\"\\nTop 10 TF-IDF terms from first document:\")\n",
        "    tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "    print(display_top_features(tfidf_features, tfidf_feature_names))\n",
        "\n",
        "    return papers_df, bow_features, tfidf_features, bow_vectorizer, tfidf_vectorizer\n"
      ],
      "metadata": {
        "id": "8jTEPIbImPHA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load SciBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "\n",
        "# 2. Helper to get [CLS] embedding\n",
        "def get_cls_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # [CLS] token\n",
        "    return cls_embedding\n",
        "\n",
        "# 3. Function to run sentiment classification\n",
        "def perform_sentiment_analysis_scibert(papers_df):\n",
        "    print(\"Extracting SciBERT embeddings...\")\n",
        "    tqdm.pandas()\n",
        "\n",
        "    # Get [CLS] embeddings for each abstract\n",
        "    papers_df['scibert_embedding'] = papers_df['abstract'].progress_apply(lambda x: get_cls_embedding(str(x)))\n",
        "\n",
        "    # Convert list of embeddings to array\n",
        "    X = np.stack(papers_df['scibert_embedding'].values)\n",
        "\n",
        "    # Assume you already have sentiment labels (positive, neutral, negative) in the dataset\n",
        "    y = papers_df['sentiment']  # You should have this column with labeled data\n",
        "\n",
        "    # 4. Split and train\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    classifiers = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "        # You can add more classifiers here\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        report = classification_report(y_test, y_pred)\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'report': report\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{name} Classification Report:\")\n",
        "        print(report)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    return papers_df, results\n"
      ],
      "metadata": {
        "id": "X1nIIoSqmQQI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Sentiment Classification Model\n",
        "def train_sentiment_classifier(papers_df, tfidf_features):\n",
        "    \"\"\"\n",
        "    Train and evaluate ML classifiers for sentiment prediction\n",
        "    \"\"\"\n",
        "    # Prepare data for classification\n",
        "    X = tfidf_features\n",
        "    y = papers_df['sentiment']\n",
        "\n",
        "    # Split data into training and testing sets using train test split 70 percent is to train\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train classifiers\n",
        "    classifiers = {\n",
        "        'Naive Bayes': MultinomialNB(),\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, classifier in classifiers.items():\n",
        "        # Train the model\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Evaluate\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'report': report,\n",
        "            'model': classifier\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\n{name} Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=classifier.classes_,\n",
        "                   yticklabels=classifier.classes_)\n",
        "        plt.title(f'Confusion Matrix - {name}')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "o2ARfXibmRb2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Compare Feature Extraction Methods\n",
        "def compare_feature_methods(papers_df, bow_features, tfidf_features):\n",
        "    \"\"\"\n",
        "    Compare BoW and TF-IDF performance for sentiment classification\n",
        "    \"\"\"\n",
        "    print(\"\\n==== COMPARING FEATURE EXTRACTION METHODS ====\")\n",
        "\n",
        "    # Function to evaluate models with different feature sets\n",
        "    def evaluate_features(X, y, feature_name):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Train classifier\n",
        "        model = MultinomialNB()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        print(f\"\\n{feature_name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy, report\n",
        "\n",
        "    # Evaluate on sentiment classification\n",
        "    y = papers_df['sentiment']\n",
        "\n",
        "    # Evaluate both feature extraction methods\n",
        "    bow_accuracy, bow_report = evaluate_features(bow_features, y, \"Bag of Words\")\n",
        "    tfidf_accuracy, tfidf_report = evaluate_features(tfidf_features, y, \"TF-IDF\")\n",
        "\n",
        "    # Compare results\n",
        "    comparison = pd.DataFrame({\n",
        "        'Feature Method': ['Bag of Words', 'TF-IDF'],\n",
        "        'Accuracy': [bow_accuracy, tfidf_accuracy],\n",
        "        'Precision (Positive)': [\n",
        "            bow_report['positive']['precision'] if 'positive' in bow_report else 0,\n",
        "            tfidf_report['positive']['precision'] if 'positive' in tfidf_report else 0\n",
        "        ],\n",
        "        'Recall (Positive)': [\n",
        "            bow_report['positive']['recall'] if 'positive' in bow_report else 0,\n",
        "            tfidf_report['positive']['recall'] if 'positive' in tfidf_report else 0\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    print(\"\\nFeature Method Comparison:\")\n",
        "    print(comparison)\n",
        "\n",
        "    # Visualize comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    comparison_melted = pd.melt(\n",
        "        comparison,\n",
        "        id_vars=['Feature Method'],\n",
        "        value_vars=['Accuracy', 'Precision (Positive)', 'Recall (Positive)'],\n",
        "        var_name='Metric',\n",
        "        value_name='Score'\n",
        "    )\n",
        "    sns.barplot(x='Metric', y='Score', hue='Feature Method', data=comparison_melted)\n",
        "    plt.title('Feature Extraction Method Comparison')\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return comparison\n"
      ],
      "metadata": {
        "id": "Xn9cCSSImTCY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this function to analyze sentiment with VADER\n",
        "def perform_sentiment_analysis(papers_df, tfidf_features=None):\n",
        "    \"\"\"\n",
        "    Analyze sentiment of papers using VADER and create sentiment labels\n",
        "    \"\"\"\n",
        "    print(\"Analyzing paper sentiment...\")\n",
        "\n",
        "    # Initialize VADER sentiment analyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Analyze sentiment for each abstract\n",
        "    sentiments = []\n",
        "    compound_scores = []\n",
        "\n",
        "    for abstract in papers_df['abstract']:\n",
        "        if not isinstance(abstract, str):\n",
        "            abstract = str(abstract)\n",
        "\n",
        "        sentiment_scores = sia.polarity_scores(abstract)\n",
        "        compound = sentiment_scores['compound']\n",
        "        compound_scores.append(compound)\n",
        "\n",
        "        # Use more balanced thresholds for academic/scientific text\n",
        "        # Scientific papers tend to be more neutral/objective\n",
        "        if compound >= 0.5:\n",
        "            sentiment = 'positive'\n",
        "        elif compound <= 0.05:  # Lower threshold for negative to catch subtle negativity\n",
        "            sentiment = 'negative'\n",
        "        else:\n",
        "            sentiment = 'neutral'\n",
        "\n",
        "        sentiments.append(sentiment)\n",
        "\n",
        "    # Add sentiment data to dataframe\n",
        "    papers_df['sentiment'] = sentiments\n",
        "    papers_df['compound_score'] = compound_scores\n",
        "\n",
        "    # Display sentiment distribution\n",
        "    sentiment_counts = papers_df['sentiment'].value_counts()\n",
        "    print(\"\\nSentiment Distribution:\")\n",
        "    print(sentiment_counts)\n",
        "\n",
        "    # Visualize distribution\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(x='sentiment', data=papers_df, order=['positive', 'neutral', 'negative'])\n",
        "    plt.title('Sentiment Distribution in Research Papers')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return papers_df, sentiment_counts"
      ],
      "metadata": {
        "id": "zUN6WgAi1_Sm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizations and Export for Tableau\n",
        "def create_visualizations(papers_df, save_directory='research_papers/visualizations'):\n",
        "    \"\"\"\n",
        "    Create visualizations for the research papers data and export for Tableau\n",
        "    \"\"\"\n",
        "    # Create directory if it doesn't exist\n",
        "    if not os.path.exists(save_directory):\n",
        "        os.makedirs(save_directory)\n",
        "        print(f\"Created directory: {save_directory}\")\n",
        "\n",
        "    # 1. Word cloud of the most common terms\n",
        "    all_words = ' '.join(papers_df['processed_abstract'])\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Word Cloud of Research Paper Abstracts')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Sentiment distribution\n",
        "    if 'sentiment' in papers_df.columns:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        sns.countplot(x='sentiment', data=papers_df, order=['positive', 'neutral', 'negative'])\n",
        "        plt.title('Sentiment Distribution of Research Papers')\n",
        "        plt.xlabel('Sentiment')\n",
        "        plt.ylabel('Number of Papers')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # 3. Text length vs. Sentiment\n",
        "    papers_df['abstract_length'] = papers_df['abstract'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x='sentiment', y='abstract_length', data=papers_df)\n",
        "    plt.title('Abstract Length by Sentiment')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Number of Words')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Export data for Tableau\n",
        "    export_for_tableau(papers_df, save_directory)\n",
        "\n",
        "    return wordcloud\n",
        "\n",
        "def export_for_tableau(papers_df, save_directory):\n",
        "    \"\"\"\n",
        "    Export processed data for Tableau visualization\n",
        "    \"\"\"\n",
        "    tableau_dir = os.path.join(save_directory, 'tableau_data')\n",
        "    if not os.path.exists(tableau_dir):\n",
        "        os.makedirs(tableau_dir)\n",
        "        print(f\"Created directory for Tableau data: {tableau_dir}\")\n",
        "\n",
        "    # 1. Export main dataset with all features\n",
        "    main_data = papers_df[['title', 'abstract', 'processed_abstract', 'published',\n",
        "                          'sentiment', 'compound_score', 'abstract_length']]\n",
        "    main_data.to_csv(os.path.join(tableau_dir, 'papers_data.csv'), index=False)\n",
        "\n",
        "    # 2. Export sentiment data\n",
        "    if 'sentiment' in papers_df.columns:\n",
        "        sentiment_counts = papers_df['sentiment'].value_counts().reset_index()\n",
        "        sentiment_counts.columns = ['sentiment', 'count']\n",
        "        sentiment_counts.to_csv(os.path.join(tableau_dir, 'sentiment_counts.csv'), index=False)\n",
        "\n",
        "    # 3. Export word frequency data\n",
        "    from collections import Counter\n",
        "    words = ' '.join(papers_df['processed_abstract']).split()\n",
        "    word_counts = Counter(words).most_common(100)\n",
        "    word_freq = pd.DataFrame(word_counts, columns=['word', 'frequency'])\n",
        "    word_freq.to_csv(os.path.join(tableau_dir, 'word_frequency.csv'), index=False)\n",
        "\n",
        "    print(f\"Exported data for Tableau to {tableau_dir}\")\n",
        "    print(\"\\nIn Tableau, you can create the following visualizations:\")\n",
        "    print(\"1. Word cloud or bar chart of most frequent terms\")\n",
        "    print(\"2. Sentiment distribution pie chart\")\n",
        "    print(\"3. Abstract length box plot by sentiment\")\n",
        "    print(\"4. Sentiment trends over time (if date data is available)\")\n",
        "    print(\"5. Interactive paper explorer with filters\")\n"
      ],
      "metadata": {
        "id": "UJezlWYOmUL_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8iZDKwv2xe9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Cell 9: Main Function and Execution\n",
        "def main():\n",
        "    print(\"=\" * 50)\n",
        "    print(\"RESEARCH PAPER TEXT ANALYTICS PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. Parameters\n",
        "    query = input(\"Enter search query (e.g., 'machine learning'): \")\n",
        "    max_results = int(input(\"Number of papers to fetch (default: 25): \") or \"25\")\n",
        "    save_directory = input(\"Save directory (default: 'research_papers'): \") or \"research_papers\"\n",
        "\n",
        "    # 2. Extract papers with citation data\n",
        "    print(\"\\nExtracting papers from arXiv...\")\n",
        "    papers_df = extract_papers_with_citations(query, max_results, save_directory)\n",
        "\n",
        "    # Display the top papers by citation count\n",
        "    print(\"\\nTop 10 Papers by Citation Count:\")\n",
        "    top_papers = papers_df.head(10)\n",
        "    for i, (idx, paper) in enumerate(top_papers.iterrows(), 1):\n",
        "        print(f\"{i}. {paper['title']} - {paper['citation_count']} citations\")\n",
        "\n",
        "    # 3. Feature extraction and preprocessing\n",
        "    print(\"\\nPreprocessing text and extracting features...\")\n",
        "    papers_df, bow_features, tfidf_features, bow_vectorizer, tfidf_vectorizer = extract_features(papers_df)\n",
        "\n",
        "    # 4. Perform sentiment analysis\n",
        "    print(\"\\nPerforming sentiment analysis...\")\n",
        "    papers_df, sentiment_results = perform_sentiment_analysis(papers_df)  # Use our new function\n",
        "\n",
        "    # 5. Train sentiment classifier\n",
        "    print(\"\\nTraining sentiment classifiers...\")\n",
        "    sentiment_classifier_results = train_sentiment_classifier(papers_df, tfidf_features)\n",
        "    # 6. Compare feature extraction methods\n",
        "    print(\"\\n Comparing feature extraction methods...\")\n",
        "    feature_comparison = compare_feature_methods(papers_df, bow_features, tfidf_features)\n",
        "\n",
        "    # 7. Create visualizations\n",
        "    print(\"\\n Creating visualizations...\")\n",
        "    visualizations_path = create_visualizations(papers_df, save_directory=os.path.join(save_directory, 'visualizations'))\n",
        "\n",
        "    # 8. Generate reflection\n",
        "    print(\"\\n Discussion and Reflection\")\n",
        "    print(\"\\nReflection on Text Analytics Process:\")\n",
        "    print(\"1. Data Collection: Extracted research papers from arXiv API\")\n",
        "    print(\"2. Preprocessing: Removed special characters, tokenized, removed stopwords, and lemmatized the text\")\n",
        "    print(\"3. Feature Extraction: Compared Bag of Words vs. TF-IDF approaches\")\n",
        "    print(\"4. Sentiment Analysis: Classified papers as positive, negative, or neutral\")\n",
        "    print(\"5. Visualization: Created visualizations to explore patterns in the data\")\n",
        "\n",
        "    # Better feature extraction method\n",
        "    better_method = \"TF-IDF\" if feature_comparison['Accuracy'][1] > feature_comparison['Accuracy'][0] else \"Bag of Words\"\n",
        "    print(f\"\\nThe {better_method} method performed better for sentiment classification.\")\n",
        "    print(f\"This is likely because {better_method == 'TF-IDF' and 'it accounts for term importance across documents' or 'it captures raw term frequency effectively'}.\")\n",
        "\n",
        "\n",
        "    # Challenges\n",
        "    print(\"\\nChallenges encountered:\")\n",
        "    print(\"- Research papers often use neutral language, making sentiment analysis challenging\")\n",
        "    print(\"- Technical terminology in research papers can be misinterpreted in sentiment analysis\")\n",
        "    print(\"- Semantic Scholar API rate limits affected citation data collection\")\n",
        "\n",
        "    # Real-world applications\n",
        "    print(\"\\nReal-world applications of text analytics:\")\n",
        "    print(\"- Automated literature review and paper recommendation systems\")\n",
        "    print(\"- Research trend identification and forecasting\")\n",
        "    print(\"- Detecting bias or sentiment patterns in academic publishing\")\n",
        "    print(\"- Improving research paper classification and keyword extraction\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ANALYSIS COMPLETE!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"\\nResults saved to '{save_directory}' directory\")\n",
        "    print(f\"Data for Tableau visualizations saved to '{save_directory}/visualizations/tableau_data'\")\n",
        "\n",
        "    return papers_df\n",
        "\n",
        "# Execute the main function when running the notebook\n",
        "if __name__ == \"__main__\":\n",
        "    papers_df = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "insg5u4FmVQK",
        "outputId": "45cd3fd6-a011-4f97-b41f-2f41233c7f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "RESEARCH PAPER TEXT ANALYTICS PIPELINE\n",
            "==================================================\n",
            "Enter search query (e.g., 'machine learning'): machine learning\n",
            "Number of papers to fetch (default: 25): 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSW_3Qj1qjrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWRue-hHmWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySfTyUZNmZXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijDJUWY0qjXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}